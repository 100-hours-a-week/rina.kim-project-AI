# 사전 학습 모델 VGG16, MobileNetV2를 활용한 Vegetable Image 분류 모델 연구 보고서

## 1. 서론

본 연구의 목적은 야채 이미지 데이터셋을 활용하여 야채의 종류를 분류하는 모델을 개발하는 것이다. 이 데이터셋은 다양한 각도와 조명에서 촬영된 야채 이미지로 구성되어 있다. 총 15가지 종류의 야채로 구분되어 있다. 본 연구를 통해 이미지 분류 기술을 적용하여 야채 종류를 자동으로 식별하는 모델을 구축하고, 그 정확도를 평가하고자 한다.

본 연구에서는 아채 이미지 데이터셋의 분류 작업을 위해 사전 훈련 모델로 VGG16과 MobileNetV2를 선택하였다. 두 모델은 이미지 인식 분야에서 널리 활용되는 대표적인 합성곱 신경망(CNN)으로, 각기 다른 구조적 특징과 강점을 보유하고 있다. VGG16은 심층적인 구조를 바탕으로 복잡한 이미지 특성을 효과적으로 추출하여 높은 정확도를 나타내지만, 상대적으로 연산량이 많고 처리 속도가 느리다는 한계를 가진다. 반면 MobileNetV2는 경량화된 모델로서 모바일과 같이 제한된 환경에서도 높은 연산 효율을 제공하지만, 복잡한 이미지의 분류 정확도에서는 다소 한계를 드러낼 수 있다. 이러한 두 모델을 성능 및 효율성 측면에서 비교 분석하여 야채 이미지 데이터셋 분류 작업에 가장 적합한 모델을 도출하고자 한다.

최근 이미지 인식 및 분류 기술은 농업 분야에서 자동화 및 효율화를 이끄는 핵심 기술로 주목받고 있다. 특히 야채와 같이 종류가 다양하고 외형이 유사한 객체는 사람이 직접 구분할 때 오차가 발생할 수 있으며, 노동력과 시간 소모도 크다. 본 연구에서 개발하고자 하는 자동 분류 모델은 이러한 한계를 극복하고, 보다 빠르고 정확한 식별을 가능하게 한다는 점에서 의의가 있다.

VGG16과 MobileNetV2 모델을 활용하여 성능과 효율성을 비교하는 것은 향후 실제 농업 현장이나 스마트팜과 같은 제한된 환경에서의 활용 가능성을 높인다는 점에서도 중요하다. 고성능의 모델 뿐만 아니라 효율성이 뛰어난 경량 모델을 함께 비교 분석함으로써 상황과 환경에 따라 유연하게 적용할 수 있는 기반을 마련할 수 있다.

따라서 본 연구는 인공지능 기반의 농업 자동화 기술 발전에 기여할 뿐 아니라, 야채 분류 정확도의 향상을 통해 농업 생산성 증대와 인력 및 자원의 절약이라는 실질적인 이점을 가져올 것으로 기대된다.
